from __future__ import annotations

import datetime as dt
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

from agents.store_agent import StoreAgent, SalesReport
from agents.production_agent import ProductionPlannerAgent
from optimizer.ga_optimizer import optimize_ga

DATA_DIR = Path(__file__).resolve().parents[0] / "data"
PLANS_DIR = DATA_DIR / "plans"
LIVE_DIR = DATA_DIR / "sales_live" 



# HELPERS

@st.cache_data(show_spinner=False)
def list_available_dates() -> list[str]:
    files = list(DATA_DIR.glob("sales_*.csv")) + list(LIVE_DIR.glob("sales_*.csv"))
    return sorted(f.stem.split("_")[1] for f in files)


def human_date(yyyymmdd: str) -> str:
    return f"{yyyymmdd[:4]}-{yyyymmdd[4:6]}-{yyyymmdd[6:]}"


@st.cache_data(show_spinner=False, ttl=60)
def get_sales(date_iso: str) -> SalesReport:
    # —Å–ø—Ä–æ–±–∞ 1 ‚Äì live-–∫–∞—Ç–∞–ª–æ–≥
    ymd = date_iso.replace("-", "")
    p_live = LIVE_DIR / f"sales_{ymd}.csv"
    if p_live.exists():
        df = pd.read_csv(p_live)
        return SalesReport(date=date_iso, df=df)

    # —Å–ø—Ä–æ–±–∞ 2 ‚Äì legacy CSV —á–µ—Ä–µ–∑ StoreAgent
    return StoreAgent(DATA_DIR).get_sales_report(date_iso)

@st.cache_data(show_spinner=False)
def material_stock_on(date_iso: str) -> pd.DataFrame:
    """–ü–æ–≤–µ—Ä—Ç–∞—î DataFrame stock_kg –¥–ª—è –∑–∞–¥–∞–Ω–æ—ó –¥–∞—Ç–∏, –≤—ñ–¥–Ω—ñ–º–∞—é—á–∏ —É—Å—ñ –ø–ª–∞–Ω–∏ ‚â§ d."""
    materials = pd.read_csv(DATA_DIR / "materials.csv").set_index("material_id")
    bom = pd.read_csv(DATA_DIR / "bom.csv")                  # qty_per_unit
    # –ø–ª–∞–Ω-—Ñ–∞–π–ª–∏ –¥–æ –æ–±—Ä–∞–Ω–æ—ó –¥–∞—Ç–∏
    ymd_limit = date_iso.replace("-", "")
    for p in PLANS_DIR.glob("plan_*.csv"):
        if p.stem.split("_")[1] > ymd_limit:
            continue
        plan = pd.read_csv(p)                                # sku, qty_produce
        if plan.empty:
            continue
        # –≤–∏—Ç—Ä–∞—Ç–∏
        use = (
            bom.merge(plan, on="sku")
               .assign(total=lambda d: d.qty_per_unit * d.qty_produce)
               .groupby("material_id")["total"].sum()
        )
        materials.loc[use.index, "stock_kg"] -= use
        # –Ω–µ –¥–∞—î–º–æ –ø—ñ—Ç–∏ –Ω–∏–∂—á–µ –Ω—É–ª—è (–¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è)
        materials["stock_kg"] = materials["stock_kg"].clip(lower=0)
    return materials.reset_index()


# SIDEBAR

st.set_page_config(page_title="Production Planner", layout="wide")
st.sidebar.title("üóÇ –î–∞–Ω—ñ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏")

# –≤–∏–±—ñ—Ä –¥–∞—Ç–∏
dates = list_available_dates()
if not dates:
    st.sidebar.warning(
        "–ù–µ–º–∞—î –∂–æ–¥–Ω–∏—Ö –ø—Ä–æ–¥–∞–∂—ñ–≤. –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∏–º—É–ª—è—Ü—ñ—é "
        "(python simulation.py) –∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ CSV –≤—Ä—É—á–Ω—É üëÜ"
    )
    st.stop()

default_idx = len(dates) - 1
sel_date = st.sidebar.selectbox(
    "–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂—ñ–≤", options=dates, format_func=human_date, index=default_idx
)
date_iso = human_date(sel_date)

# –≤–ª–∞—Å–Ω–∏–π CSV
uploaded = st.sidebar.file_uploader(
    "‚ÜóÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–≤—ñ–π sales CSV",
    type="csv",
    help="–û—á—ñ–∫—É—é—Ç—å—Å—è –∫–æ–ª–æ–Ω–∫–∏: sku, quantity_sold, stock_left",
)

# –æ–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä
algo = st.sidebar.selectbox("–û–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä", ["LP (PuLP)", "GA", "Greedy"])
algo_key = "lp" if algo.startswith("LP") else ("ga" if algo == "GA" else "heur")

# GA-–ø–∞—Ä–∞–º–µ—Ç—Ä–∏
if algo_key == "ga":
    st.sidebar.markdown("**GA –ø–∞—Ä–∞–º–µ—Ç—Ä–∏**")
    ga_pop = st.sidebar.slider("Pop size", 20, 100, 40, 10)
    ga_gen = st.sidebar.slider("Generations", 50, 300, 150, 50)
else:
    ga_pop = ga_gen = None

run_btn = st.sidebar.button("üîÑ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø–ª–∞–Ω", use_container_width=True)

# MAIN

st.title("üè≠ Production Planner")

if run_btn or "plan_df" not in st.session_state:
    # 1) –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø—Ä–æ–¥–∞–∂—ñ
    if uploaded is not None:
        sales_df = pd.read_csv(uploaded)
        sales_df.insert(0, "date", date_iso)
        report = SalesReport(date=date_iso, df=sales_df)
    else:
        report = get_sales(date_iso)

    st.subheader("–ü—Ä–æ–¥–∞–∂—ñ —Ç–∞ –∑–∞–ª–∏—à–∫–∏")
    st.dataframe(report.df, use_container_width=True)

    # 2) –∞–≥–µ–Ω—Ç-–ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫
    planner = ProductionPlannerAgent(
        DATA_DIR,
        algo="auto" if algo_key == "heur" else algo_key,
    )

    demand_df = planner._forecast_demand(report.df)  # noqa: SLA-private
    if algo_key == "ga":
        plan_df, obj_val = optimize_ga(
            demand_df,
            planner.products,
            planner.materials,
            planner.bom,
            shift_minutes=planner.SHIFT_MINUTES,
            pop_size=ga_pop,
            generations=ga_gen,
        )
    elif algo_key == "lp":
        plan = planner.handle_sales_report(report)
        plan_df, obj_val = plan.df_plan, plan.objective_value
    else:
        plan_df, obj_val = planner._heuristic_plan(demand_df)  # noqa: SLA-private

    st.session_state.plan_df = plan_df
    st.session_state.obj_val = obj_val
    st.session_state.demand_df = demand_df

# OUTPUT SECTION

plan_df: pd.DataFrame = st.session_state.get("plan_df", pd.DataFrame())
obj_val: float = st.session_state.get("obj_val", 0.0)
demand_df: pd.DataFrame = st.session_state.get("demand_df", pd.DataFrame())

col1, col2, col3 = st.columns(3)
col1.metric("üì¶ SKU —É –ø–ª–∞–Ω—ñ", len(plan_df))
col2.metric("üî® –û–¥–∏–Ω–∏—Ü—å –≤–∏—Ä–æ–±–ª–µ–Ω–æ", int(plan_df.qty_produce.sum() if not plan_df.empty else 0))
col3.metric("üí∞ –û—á—ñ–∫. –ø—Ä–∏–±—É—Ç–æ–∫", f"${obj_val:,.0f}")

# –æ–±'—î–¥–Ω–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü—è (demand vs plan)
if not plan_df.empty:
    merged = demand_df.merge(plan_df, on="sku", how="left").fillna(0)
    merged = merged.rename(columns={"need_to_cover": "need", "qty_produce": "plan"})
    st.subheader("–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø–æ—Ç—Ä–µ–±–∏ —Ç–∞ –ø–ª–∞–Ω—É")
    st.dataframe(merged[["sku", "need", "plan", "urgency"]], use_container_width=True)

    st.subheader("–ì—Ä–∞—Ñ—ñ–∫: Need vs Plan")
    chart_df = merged.set_index("sku")[["need", "plan"]]
    st.bar_chart(chart_df)
else:
    st.info("–ü–ª–∞–Ω –ø–æ—Ä–æ–∂–Ω—ñ–π ‚Äî –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –ø–æ–ø–∏—Ç—É –∞–±–æ —Å—É–≤–æ—Ä—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è.") 

# HISTORY

@st.cache_data(show_spinner=False)
def load_history() -> pd.DataFrame:
    dfs = []
    for f in PLANS_DIR.glob("history_*.csv"):
        algo = f.stem.split("_")[1]           # lp  /  ga
        df = pd.read_csv(f, parse_dates=["date"])
        df["algo"] = algo.upper()
        dfs.append(df)
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

hist_df = load_history()
if not hist_df.empty:
    # –ø—Ä–∏–±—É—Ç–æ–∫ –∑–∞ –¥–Ω—è–º–∏ –¥–ª—è –≤—Å—ñ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
    st.subheader("üìà –î–∏–Ω–∞–º—ñ–∫–∞ —Å–∏–º—É–ª—è—Ü—ñ—ó")
    st.line_chart(
        hist_df.pivot(index="date", columns="algo", values="profit"),
        use_container_width=True,
    )

    # –≤–∏–ø—É—â–µ–Ω—ñ –æ–¥–∏–Ω–∏—Ü—ñ
    st.subheader("üî® –í–∏—Ä–æ–±–ª–µ–Ω–æ –æ–¥–∏–Ω–∏—Ü—å")
    st.line_chart(
        hist_df.pivot(index="date", columns="algo", values="units_produced"),
        use_container_width=True,
    )

    # –∫—É–º—É–ª—è—Ç–∏–≤–Ω–∏–π –ø—Ä–∏–±—É—Ç–æ–∫
    st.subheader("üí∞ –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∏–π –ø—Ä–∏–±—É—Ç–æ–∫")
    cum = (
        hist_df.sort_values("date")
               .groupby("algo", group_keys=False)
               .apply(lambda d: d.assign(cum_profit=d["profit"].cumsum()))
    )
    st.area_chart(
        cum.pivot(index="date", columns="algo", values="cum_profit"),
        use_container_width=True,
    )

#  –ó–ê–õ–ò–®–ö–ò –ú–ê–¢–ï–†–Ü–ê–õ–Ü–í —Ç–∞ –†–ï–¶–ï–ü–¢–ò

# 1) –º–∞—Ç–µ—Ä—ñ–∞–ª–∏
st.subheader("üìä –ó–∞–ª–∏—à–æ–∫ –º–∞—Ç–µ—Ä—ñ–∞–ª—ñ–≤ –Ω–∞ –∫—ñ–Ω–µ—Ü—å –¥–Ω—è")
mat_df = material_stock_on(date_iso)
st.dataframe(mat_df[["material_id", "name", "stock_kg"]],
             use_container_width=True)

# 2) —Ä–µ—Ü–µ–ø—Ç—É—Ä–∏ (BOM)
st.subheader("üìã –ö—ñ–ª—å–∫—ñ—Å—Ç—å –º–∞—Ç–µ—Ä—ñ–∞–ª—É –Ω–∞ –æ–¥–∏–Ω–∏—Ü—é SKU)")
bom = pd.read_csv(DATA_DIR / "bom.csv").merge(
    pd.read_csv(DATA_DIR / "materials.csv")[["material_id", "name"]],
    on="material_id", how="left"
)
st.dataframe(bom.rename(columns={"name": "material_name"}),
             use_container_width=True) 


def apply_plan_to_stocks(plan_df: pd.DataFrame,
                         products_df: pd.DataFrame,
                         materials_df: pd.DataFrame,
                         bom_df: pd.DataFrame) -> None:
    if plan_df.empty:
        return

    # —Ç–æ–≤–∞—Ä
    for row in plan_df.itertuples():
        idx = products_df.index[products_df.sku == row.sku][0]
        products_df.at[idx, "stock_units"] += int(row.qty_produce)

    # –º–∞—Ç–µ—Ä—ñ–∞–ª–∏
    mat_lookup = bom_df.pivot_table(index="sku",
                                    columns="material_id",
                                    values="qty_per_unit",
                                    fill_value=0.0).loc[plan_df.sku]
    usage = (mat_lookup.T * plan_df.set_index("sku")["qty_produce"]).T.sum(axis=0)
    for m_id, used in usage.items():
        idx = materials_df.index[materials_df.material_id == m_id][0]
        materials_df.at[idx, "stock_kg"] = max(0.0, materials_df.at[idx, "stock_kg"] - used)

# –¥–æ–≤—ñ–¥–∫–∞: —á–∞—Å –≤–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—ñ–≤

st.subheader("‚è±Ô∏è –ß–∞—Å –≤–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—è –∫–æ–∂–Ω–æ–≥–æ SKU")
prod_time_df = (
    pd.read_csv(DATA_DIR / "products.csv")[["sku", "name", "prod_time_min"]]
      .rename(columns={"prod_time_min": "minutes_per_unit"})
)
st.dataframe(prod_time_df, use_container_width=True)